{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melindasiburian/melindacode/blob/main/Data_Mining_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5\n",
        "!pip install scipy==1.9.3\n",
        "!pip install matplotlib==3.5.3\n",
        "!pip install seaborn==0.11.2\n",
        "!pip install statsmodels==0.13.5\n",
        "!pip install pmdarima==2.0.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DukYTjAfRq18",
        "outputId": "1849d16a-9067-402a-a660-cced536089a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5.tar.gz (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Collecting scipy==1.9.3\n",
            "  Downloading scipy-1.9.3.tar.gz (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting matplotlib==3.5.3\n",
            "  Downloading matplotlib-3.5.3.tar.gz (35.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.5.3) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.3) (1.17.0)\n",
            "Building wheels for collected packages: matplotlib\n",
            "  Building wheel for matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-3.5.3-cp312-cp312-linux_x86_64.whl size=11121870 sha256=dc078b07c91143a4e8639c270b8042e25f3885c63038bd7d4cf83a9068f9a3b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/df/38/5405dc27a6524b2233addfe4367898ad06d1aa92a513ae8bcc\n",
            "Successfully built matplotlib\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.5.3 which is incompatible.\n",
            "arviz 0.22.0 requires matplotlib>=3.8, but you have matplotlib 3.5.3 which is incompatible.\n",
            "bigframes 2.18.0 requires matplotlib>=3.7.1, but you have matplotlib 3.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.5.3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "78f2b2f175394b0b9a732ff1fa82332b",
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting seaborn==0.11.2\n",
            "  Downloading seaborn-0.11.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.11.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.11.2) (1.16.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.11.2) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.12/dist-packages (from seaborn==0.11.2) (3.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=2.2->seaborn==0.11.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23->seaborn==0.11.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.23->seaborn==0.11.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn==0.11.2) (1.17.0)\n",
            "Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: seaborn\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.2\n",
            "    Uninstalling seaborn-0.13.2:\n",
            "      Successfully uninstalled seaborn-0.13.2\n",
            "Successfully installed seaborn-0.11.2\n",
            "Collecting statsmodels==0.13.5\n",
            "  Downloading statsmodels-0.13.5.tar.gz (18.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.13.5) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.13.5) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.13.5) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels==0.13.5) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->statsmodels==0.13.5) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->statsmodels==0.13.5) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.25->statsmodels==0.13.5) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.25->statsmodels==0.13.5) (1.17.0)\n",
            "Building wheels for collected packages: statsmodels\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for statsmodels \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for statsmodels (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for statsmodels\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build statsmodels\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (statsmodels)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pmdarima==2.0.3\n",
            "  Downloading pmdarima-2.0.3.tar.gz (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.9/630.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (1.5.2)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (1.16.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (0.14.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (2.5.0)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.12/dist-packages (from pmdarima==2.0.3) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima==2.0.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima==2.0.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.19->pmdarima==2.0.3) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22->pmdarima==2.0.3) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->pmdarima==2.0.3) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.13.2->pmdarima==2.0.3) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19->pmdarima==2.0.3) (1.17.0)\n",
            "Building wheels for collected packages: pmdarima\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pmdarima (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pmdarima\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for pmdarima\n",
            "Failed to build pmdarima\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pmdarima)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-F3mAwWmWsaM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "ad7a1d14-d285-4b12-ad39-fea7bf53b6b1"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'matplotlib.cm' has no attribute 'register_cmap'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-555797462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmiscplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maxisgrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m from .utils import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/cm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1580\u001b[0m     \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_r\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cmap_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m     \u001b[0mmpl_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_cmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m     \u001b[0mmpl_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_cmap_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.cm' has no attribute 'register_cmap'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XmDT78u0CjXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Global surface temperature_DM project dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "0GzIRnaADfKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tkOkpRBhE8CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicated rows\n",
        "dupes = df.duplicated()\n",
        "dupes.sum()"
      ],
      "metadata": {
        "id": "DkxyZqz-cXjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bulan_cols = ['Apr', 'May', 'Jun', 'Jul','Aug','Sep','Oct','Nov','Dec','J-D','D-N','DJF','MAM','JJA','SON']\n",
        "# Ganti nilai '***' menjadi NaN\n",
        "df[bulan_cols] = df[bulan_cols].replace(['***'], np.nan)\n",
        "# Konversi semua ke float (jika masih object)\n",
        "df[bulan_cols] = df[bulan_cols].apply(pd.to_numeric, errors='coerce')"
      ],
      "metadata": {
        "id": "G8jpEFV3HAva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.dtypes)"
      ],
      "metadata": {
        "id": "h6_iWmlMYVEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "qjals--sYcT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check and penanganan Handle Missing values"
      ],
      "metadata": {
        "id": "KIKayqWSd2r8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6myynWX2eiY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Missing values pada dataset diatasi menggunakan interpolasi linear untuk memperkirakan nilai yang hilang berdasarkan tren lokal data\n",
        "for column in df.columns:\n",
        "    if df[column].isnull().any():\n",
        "        df[column] = df[column].interpolate(method='linear')\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "9evF3zhGfDyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#missing values pada baris pertama, dilakukan imputasi menggunakan rata-rata nilai baris kedua dan ketiga.\n",
        "\n",
        "if df.iloc[0].isnull().any():\n",
        "    mean_val = df.iloc[1:3].mean()\n",
        "    df.iloc[0] = df.iloc[0].fillna(mean_val)\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "kVla2a6OfUuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary Statistik Deskriptif\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "C_qr1UeTfzuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Mean: Rata-rata anomali bulanan berada di kisaran 0.05–0.10°C, dengan bulan Maret memiliki nilai tertinggi (0.1038°C) dan Juni terendah (0.0542°C). Ini menunjukkan bahwa dibandingkan dengan rata-rata suhu historis, suhu di bulan Maret cenderung lebih hangat, sementara Juni relatif lebih stabil atau lambat naik. Meskipun perbedaan ini tampak kecil, anomali global sekecil 1°C sudah dapat berdampak besar pada pola iklim dunia, seperti mencairnya es kutub dan perubahan curah hujan.\n",
        "2. Standar Deviasi : Simpangan baku berkisar 0.39–0.45 untuk seluruh bulan dan musim, yang menunjukkan tingkat variasi anomali suhu tahunan cukup tinggi. Artinya, meskipun rata-rata suhu mungkin meningkat perlahan, fluktuasi suhu dari tahun ke tahun cukup besar. Ini penting karena bukan hanya tren rata-rata yang mempengaruhi\n",
        " iklim global, tetapi juga ketidakstabilan suhu yang menyebabkan cuaca ekstrem seperti gelombang panas, banjir, dan kekeringan.\n",
        "3. Nilai Minimum dan Maksimum : Nilai minimum anomali suhu bulanan turun hingga -0.82°C (Desember), yang kemungkinan berasal dari awal abad ke-20 atau akhir abad ke-19 ketika suhu global masih rendah. Di sisi lain, nilai maksimum mencapai hingga 1.48°C (September). Anomali sebesar itu mengindikasikan tahun-tahun terhangat yang pernah tercatat, sejalan dengan laporan IPCC bahwa beberapa tahun terakhir adalah yang terpanas sepanjang sejarah pencatatan suhu\n",
        "4. Kuartil dan penyebaran : Nilai median (50%) sebagian besar mendekati nol, tetapi nilai kuartil ketiga (75%) secara konsisten berada di atas 0.25°C. Ini berarti bahwa setidaknya 25% dari data terbaru memiliki anomali yang cukup tinggi, mendukung hipotesis bahwa pemanasan global lebih terlihat dalam data modern. Distribusi ini bersifat positively skewed (condong ke kanan), yang mencerminkan semakin banyak tahun dengan suhu lebih hangat.\n",
        "5. Jika dilihat berdasarkan musim: MAM (Mar, Apr, May) dan SON (Sep, Oct, Nov) memiliki rata-rata anomali lebih tinggi dibanding JJA (Jun, Jul, Aug). Menariknya, DJF (Dec, Jan, Feb) juga mencatat anomali yang tinggi (0.077°C), mengisyaratkan bahwa pemanasan tidak hanya terjadi di musim panas, melainkan merata di seluruh musim. Hal ini mengindikasikan bahwa iklim global mengalami pemanasan sepanjang tahun, bukan hanya terbatas pada periode tertentu.\n"
      ],
      "metadata": {
        "id": "l5_rrSMMsuAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visual Exploration"
      ],
      "metadata": {
        "id": "nTkvmxk7f_uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#visualisasi Anomali Suhu Berdasarkan Musim\n",
        "import plotly.graph_objects as go\n",
        "# Mapping of columns to season names for the legend\n",
        "season_info = {\n",
        "    'J-D': 'All Year Around',\n",
        "    'DJF': 'Dec-Jan-Feb (Northern Hem\\'s meteorological Winter)',\n",
        "    'MAM': 'Mar-Apr-May (Northern Hem\\'s meteorological Spring)',\n",
        "    'JJA': 'Jun-Jul-Aug (Northern Hem\\'s meteorological Summer)',\n",
        "    'SON': 'Sep-Oct-Nov (Northern Hem\\'s meteorological Fall)'\n",
        "}\n",
        "\n",
        "# Inisialisasi figure\n",
        "fig = go.Figure()\n",
        "\n",
        "# Tambahkan garis untuk setiap musim\n",
        "for col, title in season_info.items():\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=df['Year'],\n",
        "        y=df[col],\n",
        "        mode='lines+markers',\n",
        "        name=title\n",
        "    ))\n",
        "\n",
        "# Tambahkan layout\n",
        "fig.update_layout(\n",
        "    title='Temperature Anomalies by Season (Interactive)',\n",
        "    xaxis=dict(\n",
        "        title='Year',\n",
        "        tickmode='linear',\n",
        "        dtick=20,               # Setiap 5 tahun\n",
        "        range=[df['Year'].min(), df['Year'].max()]\n",
        "    ),\n",
        "    yaxis=dict(\n",
        "        title='Temperature Anomaly (°C)',\n",
        "        tickmode='linear',\n",
        "        dtick=0.25,             # Setiap 0.2 °C\n",
        "        range=[df[season_info.keys()].min().min() - 0.1, df[season_info.keys()].max().max() + 0.1]\n",
        "    ),\n",
        "    legend_title='Season',\n",
        "    template='plotly_white',\n",
        "    hovermode='x unified'\n",
        ")\n",
        "\n",
        "# Tampilkan grafik\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "DtbCtwUuf8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dari grafik Anomali Suhu Berdasarkan Musim (Interaktif) menunjukkan bahwa\n",
        "\n",
        "1. Pola Tren Jangka Panjang (Long-Term Trend) Garis-garis untuk semua musim (DJF - musim dingin, MAM - musim semi, JJA - musim panas, SON - musim gugur) serta rata-rata tahunan (J-D) menunjukkan tren kenaikan yang konsisten dari waktu ke waktu. Ini mengindikasikan adanya pemanasan global yang terus berlangsung.\n",
        "\n",
        "2. Keseragaman Antar Musim Walaupun tiap musim memiliki fluktuasi masing-masing, semua garis menunjukkan arah tren yang hampir paralel, yang berarti semua musim mengalami peningkatan suhu secara seragam. Ini sejalan dengan hasil analisis Mann-Kendall bahwa keempat musim menunjukkan tren naik yang signifikan.\n",
        "\n",
        "3. Fluktuasi Musiman dan Anomali Terdapat fluktuasi jangka pendek (tahun-ke-tahun) yang terlihat dalam bentuk “zig-zag” pada grafik. Fluktuasi ini wajar terjadi karena pengaruh fenomena alam jangka pendek (misalnya El Niño, letusan gunung berapi, atau aktivitas matahari), namun tidak menutupi tren kenaikan jangka panjang.\n",
        "\n",
        "4. Kenaikan Signifikan Setelah 1980 Titik balik yang signifikan terlihat setelah tahun 1980, di mana suhu mulai meningkat dengan lebih cepat. Ini sesuai dengan hasil analisis change point detection yang mengidentifikasi 1980 sebagai salah satu titik perubahan utama."
      ],
      "metadata": {
        "id": "tnlNdmNFDcIp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deteksi & Visualisasi Outliers"
      ],
      "metadata": {
        "id": "jgVjVyKDju95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Deteksi outlier dilakukan dengan metode Interquartile Range (IQR) dan Z-Score"
      ],
      "metadata": {
        "id": "sEqIyUMFr6fO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IQR Method"
      ],
      "metadata": {
        "id": "udDpvqAtjwM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df['J-D'].quantile(0.25)\n",
        "Q3 = df['J-D'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Find outliers\n",
        "outliers = df[(df['J-D'] < lower_bound) | (df['J-D'] > upper_bound)]\n",
        "print(\"Outliers:\\n\", outliers)"
      ],
      "metadata": {
        "id": "o77d97gwjtBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-Score Method"
      ],
      "metadata": {
        "id": "QhZ7TYXSkXAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "\n"
      ],
      "metadata": {
        "id": "z-w-N0VToMc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "z_score = zscore(df['SON']) #Z-Score = (nilai - rata-rata) / standar deviasi, Jika Z-Score > 3 atau < -3, maka nilai itu sangat tidak biasa dan dianggap sebagai outlier.\n",
        "print(z_score)\n",
        "threshold = 3 # 3 SDs away from the mean\n",
        "\n",
        "ol = df[abs(z_score) > threshold]\n",
        "print(ol)"
      ],
      "metadata": {
        "id": "VUcn5wU3jf7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outlier divisualisasikan menggunakan boxplot untuk memahami distribusi dan potensi nilai ekstrim."
      ],
      "metadata": {
        "id": "5nI1BN2WsEML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(y=df['J-D'], color=sns.color_palette()[0])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nkW4XRn-ktSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Suhu Global Didominasi oleh Nilai Netral hingga Sedikit Positif Sebagian besar data berada di antara sekitar -0.2°C hingga +0.3°C, menunjukkan bahwa fluktuasi suhu global relatif moderat dalam kurun waktu panjang.\n",
        "Median di Sekitar Nol Median anomali suhu mendekati 0°C, menandakan bahwa selama lebih dari satu abad, setengah dari tahun-tahun dalam dataset mengalami suhu global yang hanya sedikit berbeda dari rerata 1951–1980.\n",
        "\n",
        "2. Adanya Outlier Positif Terdapat titik-titik outlier di atas batas atas boxplot (sekitar +1.1 hingga +1.3°C), yang mengindikasikan beberapa tahun terakhir mengalami suhu global yang sangat tinggi dibandingkan tahun-tahun sebelumnya. Ini mendukung bukti pemanasan global yang makin ekstrem.\n",
        "\n",
        "3. Distribusi Tidak Simetris (Positively Skewed) Distribusi cenderung miring ke kanan, yang berarti lebih banyak kejadian suhu ekstrem tinggi dibandingkan suhu ekstrem rendah di era modern."
      ],
      "metadata": {
        "id": "zN73EpkaDj01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the color palette to 'colorblind'\n",
        "palette = sns.color_palette(\"colorblind\") #Memilih palet warna yang ramah bagi penderita buta warna\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "# Loop through each column (excluding 'Year')\n",
        "for i, column in enumerate(df.columns.drop('Year')):\n",
        "    # Create a subplot for each column\n",
        "    plt.subplot(3, 6, i+1)\n",
        "    # Use modulo to cycle through the colorblind-friendly palette\n",
        "    color = palette[i % len(palette)]\n",
        "    sns.boxplot(y=df[column], color=color) #Menampilkan boxplot tiap kolom\n",
        "    plt.title(column)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wJW1VNpsk6pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sebaran Suhu Relatif Konsisten di Semua Bulan Hampir semua boxplot bulanan memiliki rentang interkuartil (IQR) yang mirip: dari sekitar -0.4°C hingga +0.4°C. Ini menandakan bahwa anomali suhu tidak terlalu dipengaruhi oleh bulan tertentu secara drastis, meskipun ada fluktuasi minor.\n",
        "\n",
        "2. Adanya Outlier Positif di Hampir Semua Bulan dan Musim Setiap bulan dan musim menampilkan outlier di atas batas atas, menandakan tahun-tahun dengan suhu jauh lebih tinggi dari biasanya. Terutama terlihat di Feb, Mar, Apr, May, Oct, dan DJF memperkuat bukti pemanasan ekstrem pada musim dingin dan transisi.\n",
        "\n",
        "3. Tidak Ada Musim yang Bebas dari Pemanasan Musim DJF, MAM, JJA, dan SON semua menunjukkan peningkatan suhu dengan outlier.Hal ini menunjukkan bahwa pemanasan global bersifat lintas-musim, tidak hanya terjadi di musim panas saja.\n",
        "\n",
        "4. Distribusi Positively Skewed (Miring ke Kanan) Hampir semua boxplot memiliki median yang cenderung lebih dekat ke batas bawah IQR. Ini mengindikasikan bahwa kasus suhu ekstrem tinggi lebih sering terjadi dibandingkan suhu ekstrem rendah."
      ],
      "metadata": {
        "id": "itWBqNdGDpha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Heatmap"
      ],
      "metadata": {
        "id": "Azn4j-gYlHeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "months_columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "df_months = df[months_columns]\n",
        "\n",
        "corr_matrix = df_months.corr()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr_matrix,\n",
        "            annot = True, # Menampilkan nilai korelasi di setiap sel\n",
        "            cmap='flare', # Skema warna\n",
        "            linewidth=3, # Ketebalan garis antar sel\n",
        "            square=True) # Membuat sel persegi\n",
        "plt.title('Correlation Matrix Heatmap for January to December (1880-2025)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fJvDWOXvlFC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmap korelasi antara bulan Januari hingga Desember dari dataset suhu permukaan global (1880–2025) menunjukkan bahwa secara umum terdapat hubungan yang sangat kuat antara anomali suhu bulanan. Nilai korelasi yang tinggi, sebagian besar di atas 0.90, mengindikasikan bahwa jika terjadi peningkatan suhu di suatu bulan, besar kemungkinan bulan-bulan lain juga mengalami tren serupa. Korelasi paling kuat terlihat antara bulan-bulan yang berdekatan secara kronologis seperti April–Mei dan Mei–Juni, yang menunjukkan adanya transisi suhu yang gradual dan konsisten antar musim. Sebaliknya, korelasi relatif lebih rendah terjadi antara bulan-bulan yang berjauhan, seperti Januari dan Desember, namun tetap menunjukkan nilai yang signifikan (sekitar 0.85), mencerminkan bahwa pola pemanasan global bersifat menyeluruh sepanjang tahun. Pola korelasi yang tinggi antar bulan selama lebih dari satu abad ini mempertegas bahwa perubahan suhu global bersifat stabil dan sistemik, tidak terbatas pada waktu atau musim tertentu saja. Hal ini mengimplikasikan bahwa dampak pemanasan global seperti gelombang panas atau kekeringan cenderung tidak hanya terjadi musiman, tetapi bisa meluas ke seluruh periode tahunan."
      ],
      "metadata": {
        "id": "K8tX3jCttFK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Heatmap korelasi musiman antara anomali suhu global dari tahun 1880 hingga 2025\n",
        "season_columns = ['DJF', 'MAM', 'JJA', 'SON'] # winter, spring, summer, fall\n",
        "df_seasons = df[season_columns]\n",
        "\n",
        "corr_matrix_seasons = df_seasons.corr()\n",
        "season_labels = ['Winter (DJF)', 'Spring (MAM)', 'Summer (JJA)', 'Fall (SON)']\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr_matrix_seasons,\n",
        "            annot = True,\n",
        "            cmap='crest',\n",
        "            linewidth=3,\n",
        "            xticklabels=season_labels,\n",
        "            yticklabels=season_labels,\n",
        "            square=True)\n",
        "plt.title('Correlation Matrix Heatmap for Each Seasons (1880-2025)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OacuU_GclVsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmap korelasi musiman antara anomali suhu global dari tahun 1880 hingga 2025 menunjukkan bahwa setiap musim memiliki korelasi yang sangat tinggi satu sama lain, dengan nilai antara 0.92 hingga 0.97. Musim semi (MAM) dan musim panas (JJA) mencatat korelasi tertinggi (0.97), yang menunjukkan bahwa perubahan suhu global pada periode ini sangat selaras dan kemungkinan besar mengalami tren pemanasan yang konsisten. Sementara itu, korelasi paling rendah tercatat antara musim dingin (DJF) dan musim gugur (SON) yaitu 0.92, meskipun nilai ini masih menunjukkan hubungan yang kuat. Hal ini mengindikasikan bahwa meskipun setiap musim memiliki ciri khas iklim masing-masing, tren jangka panjang seperti pemanasan global telah memberikan dampak yang menyeluruh dan seragam pada semua musim. Korelasi tinggi ini mencerminkan bahwa tren kenaikan suhu bukan hanya fenomena musiman, melainkan mempengaruhi sistem iklim secara keseluruhan sepanjang tahun."
      ],
      "metadata": {
        "id": "yEDm-D9GtL5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.drop(columns=['Year'])\n",
        "corr_matrix2 = new_df.corr()\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(corr_matrix2,\n",
        "            annot = True,\n",
        "            cmap='Blues',\n",
        "            square=True)\n",
        "plt.title('Correlation Matrix Heatmap at Large')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XCA0_yjelgYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OBSERVATION FROM HEATMAPS"
      ],
      "metadata": {
        "id": "bN10jiQ0lwVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisis Korelasi Antara Variabel Bulanan dan Musiman\n",
        "\n",
        "Korelasi yang tinggi antar bulan : Heatmap korelasi suhu bulanan (1880–2025) menunjukkan hubungan kuat antar bulan, terutama antara bulan-bulan berurutan seperti April–Mei dan Mei–Juni. Meskipun korelasi terendah terjadi antara bulan yang berjauhan seperti Januari–Desember (0.85), secara keseluruhan pola suhu menunjukkan konsistensi tren pemanasan global sepanjang tahun.\n",
        "\n",
        "Seosanal Correlation : Heatmap korelasi musiman suhu global (1880–2025) menunjukkan hubungan yang sangat kuat antar musim, dengan nilai korelasi 0.92–0.97. Korelasi tertinggi terjadi antara musim semi dan musim panas (0.97), menandakan tren pemanasan yang konsisten. Meskipun musim dingin dan gugur memiliki korelasi paling rendah (0.92), nilainya tetap tinggi, menunjukkan bahwa perubahan suhu global berdampak merata sepanjang tahun tanpa terikat musim tertentu."
      ],
      "metadata": {
        "id": "tW1SaVPSlzGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trend Analysis**"
      ],
      "metadata": {
        "id": "9wYB5Q_vgoJY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rate of Change"
      ],
      "metadata": {
        "id": "YAGw6QwMh5hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#   Analisis Tren Linear Anomali Suhu Global (1880-2025)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Mapping of columns to season names\n",
        "season_names = {\n",
        "    'J-D': 'All Year',\n",
        "    'DJF': 'Winter',\n",
        "    'MAM': 'Spring',\n",
        "    'JJA': 'Summer',\n",
        "    'SON': 'Fall'\n",
        "}\n",
        "\n",
        "X = df['Year'].values.reshape(-1, 1) #'Year' menjadi array 2 dimensi\n",
        "for col, season in season_names.items(): #loop setiap musim\n",
        "    y = df[col]\n",
        "\n",
        "    model = LinearRegression().fit(X, y)\n",
        "    print(f\"\\nTrend Analysis for {col}:\")\n",
        "    print(f\"Slope: {model.coef_[0]}\")\n",
        "    print(f\"Intercept: {model.intercept_}\")\n",
        "\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(df['Year'], y, label='Observed')\n",
        "    plt.plot(df['Year'], y_pred, color='red', label='Fitted Line')\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel(f'Temperature Anomaly ({season})')\n",
        "    plt.title(f'Temperature Anomaly with Linear Trend Line ({season})')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_ZQawn1PlplG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gambar diatas menunjukkan visualisasi tren linier anomali suhu dari tahun 1880 hingga 2025 untuk periode tahunan (J-D), serta setiap musim secara terpisah: DJF (musim dingin), MAM (musim semi), JJA (musim panas), dan SON (musim gugur). Setiap grafik memuat garis regresi linier (warna merah) yang menggambarkan arah perubahan suhu dari waktu ke waktu. Kemiringan garis (slope) pada masing-masing grafik menunjukkan laju peningkatan suhu per tahun.\n",
        "Seluruh periode baik tahunan maupun musiman menunjukkan tren yang meningkat (slope > 0), menandakan pemanasan global yang konsisten di semua musim. Nilai slope terbesar terlihat pada musim gugur (SON) dengan kenaikan sekitar 0.0091°C per tahun, diikuti oleh musim panas (JJA), musim dingin (DJF), dan musim semi (MAM). Hal ini menegaskan bahwa perubahan iklim tidak terbatas pada satu musim saja, melainkan terjadi secara sistematis sepanjang tahun. Tren positif yang kuat di semua musim mendukung urgensi mitigasi terhadap perubahan iklim global."
      ],
      "metadata": {
        "id": "brhaic2FD8_1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving Average Method"
      ],
      "metadata": {
        "id": "6pleyVyvibRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tren Anomali Suhu Menggunakan Metode Moving Average 3 Tahun dan 10 Tahun\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "palette = sns.color_palette(\"colorblind\", 3)\n",
        "window_size = 3 # try different size of window #rata-rata 3 tahun terakhir.\n",
        "df['Moving_Avg'] = df['J-D'].rolling(window=window_size).mean() #menghitung rata-rata dari window yang bergeser.\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(df['Year'], df['J-D'], alpha=0.6, label='Observed Anomaly')\n",
        "plt.plot(df['Year'], df['Moving_Avg'], color=palette[1], label=f'{window_size}-Year Moving Average')\n",
        "plt.plot(df['Year'], y_pred, color=palette[2], label='Linear Trend Line')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly')\n",
        "plt.title(f'Temperature Anomaly with {window_size}-Year Moving Average')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unDFxgjniKor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode moving average digunakan dalam analisis deret waktu untuk menghaluskan fluktuasi jangka pendek dan menyoroti tren jangka panjang dalam data. Pada studi ini, diterapkan rata-rata bergerak selama 3 tahun terhadap anomali suhu global sepanjang tahun (kolom J-D) untuk mengidentifikasi pola perubahan suhu yang lebih jelas dari waktu ke waktu.\n",
        "\n",
        "Visualisasi hasil menunjukkan bahwa garis 3-Year Moving Average (garis oranye) mengikuti pola umum dari data asli yang tersebar (titik biru), namun dengan tingkat fluktuasi yang lebih halus. Hal ini membantu mengurangi dampak dari variabilitas tahun-ke-tahun yang dapat disebabkan oleh faktor sementara seperti fenomena El Niño, letusan gunung berapi, atau variabel iklim jangka pendek lainnya.\n",
        "\n",
        "Garis tren linier (garis hijau) juga ditambahkan untuk memberikan estimasi laju peningkatan jangka panjang suhu anomali secara keseluruhan. Dapat diamati bahwa baik rata-rata bergerak maupun tren linier sama-sama menunjukkan tren peningkatan suhu yang konsisten dan signifikan sejak awal abad ke-20 hingga tahun 2023, memperkuat bukti adanya pemanasan global.\n",
        "\n",
        "Penggunaan moving average sangat bermanfaat dalam menyederhanakan visualisasi pola data dan mendukung interpretasi tren jangka panjang dalam konteks perubahan iklim global."
      ],
      "metadata": {
        "id": "bRcrKsySEB5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tren Anomali Suhu Menggunakan Metode Moving Average 3 Tahun dan 10 Tahun\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "palette = sns.color_palette(\"colorblind\", 3)\n",
        "window_size = 3 # try different size of window\n",
        "df['Moving_Avg_S'] = df['MAM'].rolling(window=window_size).mean()\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(df['Year'], df['MAM'], alpha=0.6, label='Observed Anomaly')\n",
        "plt.plot(df['Year'], df['Moving_Avg_S'], color=palette[1], label=f'{window_size}-Year Moving Average')\n",
        "plt.plot(df['Year'], y_pred, color=palette[2], label='Linear Trend Line')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly')\n",
        "plt.title(f'Temperature Anomaly with {window_size}-Year Moving Average (Spring)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vz5rBMPbjDwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving Average Method (Spring)\n",
        "\n",
        "Pada visualisasi ini, digunakan 3-Year Moving Average terhadap anomali suhu musim semi (MAM – Maret, April, Mei) untuk periode 1880 hingga 2023. Pendekatan ini memungkinkan identifikasi tren iklim musiman tanpa terdistorsi oleh variabilitas tahunan ekstrem.\n",
        "\n",
        "Dari grafik terlihat bahwa kurva rata-rata bergerak (garis oranye) berhasil menangkap pola umum pergerakan suhu anomali musiman secara lebih halus dibandingkan data aktual (titik biru). Sementara itu, garis tren linier (garis hijau) menunjukkan adanya kecenderungan kenaikan suhu yang konsisten selama lebih dari satu abad, yang menegaskan adanya tren pemanasan yang signifikan selama musim semi.\n",
        "\n",
        "Penggunaan moving average jangka pendek seperti 3 tahun menjaga sensitivitas terhadap perubahan iklim musiman yang cepat, sembari tetap menyaring noise acak dari tahun ke tahun. Hasil ini mendukung bukti ilmiah terkait perubahan iklim global, khususnya pada musim semi di belahan bumi utara, yang mengalami peningkatan suhu rata-rata secara signifikan."
      ],
      "metadata": {
        "id": "xZC6dfoGEEtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical Analysis**"
      ],
      "metadata": {
        "id": "SgeTNER6jM8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "a208ujFWjPAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Q-Q Plot\n",
        "\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "seasons = ['DJF', 'MAM', 'JJA', 'SON']\n",
        "\n",
        "for season in seasons:\n",
        "    plt.figure()\n",
        "    stats.probplot(df[season], dist=\"norm\", plot=plt) # Menghasilkan data kuantil yang digunakan untuk membandingkan distribusi data dengan distribusi normal.\n",
        "    plt.title(f'Q-Q Plot for {season}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "vff_iVykjJBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Normalitas Menggunakan Q-Q Plot Sebelum melakukan analisis varians (ANOVA), salah satu asumsi penting yang harus dipenuhi adalah bahwa data residual pada masing-masing kelompok bersifat normal. Oleh karena itu, dilakukan uji visual terhadap distribusi data menggunakan Quantile-Quantile (Q-Q) Plot untuk masing-masing musim: DJF (Winter), MAM (Spring), JJA (Summer), dan SON (Fall).\n",
        "\n",
        "Pada grafik Q-Q plot, data dikatakan mendekati distribusi normal jika titik-titik data terletak di sepanjang garis diagonal merah. Namun, dari hasil visualisasi pada keempat musim, tampak bahwa titik-titik tidak mengikuti garis secara sempurna, terutama di bagian ekor distribusi (nilai ekstrem). Hal ini menunjukkan penyimpangan dari distribusi normal.\n",
        "\n",
        "Penyimpangan yang paling jelas terlihat pada musim SON dan JJA, di mana deviasi dari garis referensi semakin mencolok pada kuartil atas dan bawah. Kondisi ini menunjukkan adanya skewness dan kurtosis yang mengindikasikan bahwa data tidak sepenuhnya memenuhi asumsi normalitas.\n",
        "\n",
        "Karena pelanggaran terhadap asumsi normalitas ini, terutama pada ukuran sampel yang relatif kecil, penggunaan metode parametrik seperti One-Way ANOVA menjadi kurang tepat. Oleh karena itu, sebagai alternatif yang lebih sesuai, digunakan metode non-parametrik seperti Kruskal-Wallis H-Test, yang tidak mengasumsikan distribusi tertentu dari data residual."
      ],
      "metadata": {
        "id": "BWGg6eMiEIzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "for season in seasons:\n",
        "    stat, p = shapiro(df[season]) # Menghitung statistik uji dan p-value untuk uji Shapiro-Wilk\n",
        "    print(f'{season}: Statistics={stat}, p={p}')\n",
        "    if p > 0.05:\n",
        "        print('Sample looks Gaussian (fail to reject H0)')\n",
        "    else:\n",
        "        print('Sample does not look Gaussian (reject H0)')"
      ],
      "metadata": {
        "id": "s8LxAsD8jl_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Normalitas Menggunakan Shapiro-Wilk Untuk mengevaluasi apakah distribusi data musiman mengikuti distribusi normal, dilakukan uji Shapiro-Wilk terhadap empat kelompok musim, yaitu DJF (Winter), MAM (Spring), JJA (Summer), dan SON (Fall). Uji ini digunakan secara luas untuk mendeteksi normalitas, khususnya pada ukuran sampel kecil hingga sedang, dengan hipotesis nol (H₀) bahwa data berasal dari distribusi normal.\n",
        "\n",
        "Karena seluruh p-value berada jauh di bawah ambang signifikansi 0.05, maka hipotesis nol (H₀) ditolak untuk keempat musim. Artinya, data anomali suhu musiman tidak mengikuti distribusi normal.\n",
        "\n",
        "Temuan ini diperkuat oleh hasil visualisasi Q-Q Plot sebelumnya yang juga menunjukkan deviasi dari garis normal teoretis. Dengan demikian, penggunaan metode parametrik seperti One-Way ANOVA menjadi kurang tepat dalam kasus ini, dan pendekatan non-parametrik seperti Kruskal-Wallis H-Test lebih sesuai karena tidak mensyaratkan asumsi distribusi normal."
      ],
      "metadata": {
        "id": "SdXZ3uyvj0cU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Kruskal-Willis Test"
      ],
      "metadata": {
        "id": "JVWCMhQPj7e4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hipotesis nol (H₀): Tidak ada perbedaan signifikan dalam distribusi nilai (median atau peringkat) anomali suhu di antara keempat musim (DJF, MAM, JJA, SON).\n",
        "\n",
        "Hipotesis alternatif (H₁): Terdapat paling tidak satu musim yang memiliki distribusi anomali suhu yang berbeda secara signifikan dari yang lain, yang menunjukkan bahwa tidak semua kelompok musim berasal dari populasi dengan distribusi yang sama.\n",
        "\n",
        "Uji Kruskal-Wallis digunakan sebagai alternatif dari One-Way ANOVA ketika asumsi normalitas tidak terpenuhi. Uji ini mengandalkan peringkat data daripada nilai aslinya, sehingga lebih robust terhadap outlier dan distribusi yang tidak normal."
      ],
      "metadata": {
        "id": "mjSZjphmkOpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import pandas as pd\n",
        "\n",
        "season_data = df[['DJF', 'MAM', 'JJA', 'SON']].stack()\n",
        "\n",
        "# Creating a new data structure\n",
        "season_df = pd.DataFrame({'Season': season_data.index.get_level_values(1), 'Anomaly': season_data.values})\n",
        "print(season_df)\n",
        "\n",
        "# Kruskal-Wallis test\n",
        "h_stat, p_value = stats.kruskal(season_df[season_df['Season'] == 'DJF']['Anomaly'],\n",
        "                                season_df[season_df['Season'] == 'MAM']['Anomaly'],\n",
        "                                season_df[season_df['Season'] == 'JJA']['Anomaly'],\n",
        "                                season_df[season_df['Season'] == 'SON']['Anomaly'])\n",
        "print(\"Kruskal-Wallis Test Results: H-Stat =\", h_stat, \", P-value =\", p_value)"
      ],
      "metadata": {
        "id": "-DJhQ1Nsjtba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall statsmodels\n"
      ],
      "metadata": {
        "id": "YIzNCI-tQtnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "H-statistik mengukur seberapa besar perbedaan peringkat antar kelompok (musim) dibandingkan dengan yang diharapkan jika semua kelompok berasal dari distribusi yang sama. Nilai H-statistik yang rendah, seperti yang diperoleh (H = 0.565), menunjukkan bahwa tidak terdapat deviasi substansial dari hipotesis nol, artinya tidak ada perbedaan distribusi yang mencolok antar musim.\n",
        "\n",
        "P-value sebesar 0.904 mengindikasikan bahwa probabilitas mendapatkan hasil seperti ini (atau yang lebih ekstrem) jika hipotesis nol benar sangat tinggi, jauh di atas ambang batas signifikansi umum (α = 0.05). Dengan demikian, kita tidak memiliki cukup bukti untuk menolak hipotesis nol."
      ],
      "metadata": {
        "id": "PVgrM5SZk0Pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation\n",
        "\n",
        "Nilai p-value yang sangat tinggi (di atas 0.05) menunjukkan bahwa tidak ada cukup bukti untuk menolak Hipotesis Nol (H₀). Ini berarti tidak ada perbedaan yang signifikan secara statistik dalam rata-rata anomali suhu antar musim (DJF, MAM, JJA, SON). Jadi, variasi yang muncul dalam data bisa jadi hanya karena faktor kebetulan atau fluktuasi alami, bukan karena perbedaan mendasar antar musim."
      ],
      "metadata": {
        "id": "kfkoFWGRk5c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Series Decomposition"
      ],
      "metadata": {
        "id": "kWAqFWq-lBU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekomporsi deret waktu melibatkan pemisahan deret waktu menjadi beberapa komponen (Tren, Musiman, dan Residual)."
      ],
      "metadata": {
        "id": "D4X0wQ2VlJKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "# Convert year to datetime format to prepare for seasonal_decompose\n",
        "df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n",
        "df.set_index('Year', inplace=True)\n",
        "# Melakukan dekomposisi data time series\n",
        "result = seasonal_decompose(df['J-D'], model='additive')\n",
        "\n",
        "result.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5xAJWpvzklEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trend Component: Grafik komponen tren menunjukkan kenaikan jangka panjang dalam anomali suhu global, meskipun dengan fluktuasi. Ini adalah indikasi kuat adanya tren pemanasan global dari waktu ke waktu.\n",
        "\n",
        "Seasonal Component: Komponen musiman (seasonal) berupa garis datar di sekitar nol menunjukkan bahwa tidak ada pola musiman yang signifikan dalam data ini. Dengan kata lain, data ini tidak menunjukkan variasi tetap yang berulang berdasarkan musim.\n",
        "\n",
        "Residual Component: Komponen residual yang berkisar dekat angka nol dan terlihat sebagai garis padat menunjukkan bahwa fluktuasi acak masih ada, tetapi sebagian besar variasi dalam data sudah dijelaskan oleh komponen tren. Sisanya merupakan noise atau variabilitas tak terjelaskan, kemungkinan disebabkan oleh fenomena iklim yang tak terdeteksi oleh model."
      ],
      "metadata": {
        "id": "7swikCsTljSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mann-Kendall Trend Test"
      ],
      "metadata": {
        "id": "YdNONS53mCEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Tren Mann-Kendall adalah uji non-parametrik yang digunakan untuk mengidentifikasi dan mengonfirmasi tren dalam data deret waktu. Uji ini dapat membantu mengonfirmasi apakah tren tersebut signifikan secara statistik, tanpa memerlukan asumsi distribusi data tertentu."
      ],
      "metadata": {
        "id": "vjdtQUbgmFG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hipotesis Nol (H0): Tidak ada tren dalam anomali suhu seiring waktu untuk musim yang diberikan.\n",
        "\n",
        "Hipotesis Alternatif (H1): Terdapat tren dalam anomali suhu seiring waktu untuk musim yang diberikan."
      ],
      "metadata": {
        "id": "v7r7n7U7mF1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymannkendall"
      ],
      "metadata": {
        "id": "f8qwAmJallAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M-K Trend Test for All-Year"
      ],
      "metadata": {
        "id": "jWfw4OuCmVzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pymannkendall as mk\n",
        "\n",
        "result = mk.original_test(df['J-D']) #uji non-parametrik yang digunakan untuk mendeteksi tren monotonic (naik atau turun) dalam data deret waktu tanpa asumsi distribusi normal.\n",
        "\n",
        "print(f\"Trend: {result.trend}\")\n",
        "print(f\"P-value: {result.p}\")\n",
        "print(f\"Z-value: {result.z}\")\n",
        "print(f\"Slope (Sen's slope): {result.slope}\")"
      ],
      "metadata": {
        "id": "8TwnszGNmWTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Tren Mann-Kendall untuk Data Tahunan (J-D) Hasil uji Mann-Kendall menunjukkan adanya tren peningkatan signifikan dalam data anomali suhu tahunan global. Nilai Z = 13.056 menunjukkan tren positif yang sangat kuat, sedangkan p-value = 0.0 mengindikasikan bahwa tren tersebut sangat signifikan secara statistik.\n",
        "\n",
        "Kemiringan Sen (Sen's Slope) sebesar +0.0082°C/tahun berarti bahwa anomali suhu global mengalami peningkatan rata-rata sebesar 0.008 derajat Celcius setiap tahun.\n",
        "\n",
        "Dengan demikian, uji ini memberikan bukti kuat atas keberadaan tren pemanasan global jangka panjang."
      ],
      "metadata": {
        "id": "cQSjH9H4mfYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "M-K Trend Test for Seasonal"
      ],
      "metadata": {
        "id": "g1757TCGmlK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Different seasons might be differently affected by climate change."
      ],
      "metadata": {
        "id": "P3XvnlhUmpdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seasons = ['DJF','MAM','JJA','SON']\n",
        "\n",
        "mk_results = {}\n",
        "for season in seasons: #Looping M-K Test untuk Setiap Musim\n",
        "    result = mk.original_test(df[season])\n",
        "    #print(result)\n",
        "    mk_results[season] = {\n",
        "        'Trend': result.trend,\n",
        "        'P-value': result.p,\n",
        "        'Z-value': result.z,\n",
        "        'Slope': result.slope\n",
        "    }\n",
        "    print(mk_results[season]) # Menyimpan trend, p-value, z-value, dan slope untuk masing-masing musim dalam dictionary\n",
        "\n",
        "for season, results in mk_results.items():\n",
        "    print(f\"Season: {season}, Results: {results}\")"
      ],
      "metadata": {
        "id": "nOqha3b4meMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "Interpretasi Hasil Uji Tren Mann-Kendall Musiman: Uji tren Mann-Kendall yang dilakukan pada data anomali suhu musiman (DJF, MAM, JJA, SON) menunjukkan bahwa semua musim mengalami tren peningkatan yang signifikan secara statistik, dengan p-value = 0.0 dan nilai Z berkisar antara 11.97 hingga 12.83.\n",
        "\n",
        "Estimasi Kemiringan Sen (Sen’s Slope) untuk setiap musim berkisar antara +0.0076°C hingga +0.0086°C per tahun, menunjukkan bahwa laju peningkatan suhu berlangsung secara relatif seragam sepanjang tahun.\n",
        "\n",
        "Hasil ini memperkuat bukti bahwa pemanasan global tidak hanya terjadi pada musim tertentu, melainkan berdampak pada seluruh musim dengan tren yang konsisten. Konsistensi ini memperlihatkan kekuatan dan cakupan luas sinyal pemanasan dalam sistem iklim."
      ],
      "metadata": {
        "id": "ILZpBC6tm-B6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change Point Analysis"
      ],
      "metadata": {
        "id": "-Eav1zLSnJ-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify points in time where the statistical properties of a time series change"
      ],
      "metadata": {
        "id": "KMjDeZUwnM40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ruptures"
      ],
      "metadata": {
        "id": "yvFbYtO-mQVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change Point Detection for All-Year"
      ],
      "metadata": {
        "id": "S0NvGhxMnoBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Baca ulang dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Global surface temperature_DM project dataset.csv')\n",
        "\n",
        "# 2. Ganti semua '***' dan nilai kosong menjadi NaN\n",
        "df.replace(['***'], np.nan, inplace=True)\n",
        "\n",
        "# 3. Konversi kolom Apr, May, Jun, Jul menjadi float\n",
        "for col in ['Apr', 'May', 'Jun', 'Jul','Aug','Sep','Oct','Nov','Dec','J-D','D-N','DJF','MAM','JJA','SON']: #Mengonversi nilai dalam kolom bulan dan agregat musim menjadi tipe data numerik.\n",
        "\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# 4. Interpolasi nilai NaN di seluruh kolom secara linear\n",
        "for column in df.columns:\n",
        "    if df[column].isnull().any():\n",
        "        df[column] = df[column].interpolate(method='linear')\n",
        "\n",
        "# 5. Isi NaN di baris pertama (jika masih ada) dengan rata-rata baris 1 dan 2\n",
        "if df.iloc[0].isnull().any():\n",
        "    mean_val = df.iloc[1:3].mean(numeric_only=True)\n",
        "    df.iloc[0] = df.iloc[0].fillna(mean_val)\n",
        "\n",
        "# 6. Lihat hasil\n",
        "df.head()"
      ],
      "metadata": {
        "id": "onYhDKponsfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change Point Analysis bertujuan untuk mengidentifikasi titik-titik dalam deret waktu di mana terjadi perubahan signifikan dalam pola statistik data, seperti perubahan tren rata-rata atau variansi. Metode ini sangat penting dalam konteks analisis iklim, karena membantu mengungkap momen-momen kritis dalam sejarah suhu global yang mungkin terkait dengan fenomena besar seperti industrialisasi, kebijakan lingkungan, atau aktivitas vulkanik.\n",
        "\n",
        "Berdasarkan visualisasi hasil analisis Change Point Detection untuk anomali suhu global tahunan (J-D), dapat diidentifikasi lima titik perubahan utama yang mengindikasikan adanya pergeseran pola iklim secara statistik. Dengan menggunakan metode Binary Segmentation dari pustaka ruptures, sistem mendeteksi waktu-waktu di mana tren suhu menunjukkan pergeseran tajam"
      ],
      "metadata": {
        "id": "8gEPo-FFE5fB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ruptures as rpt\n",
        "\n",
        "points = df[\"J-D\"].values\n",
        "print(points)\n",
        "\n",
        "# Search, binary segmentation\n",
        "algo = rpt.Binseg(model=\"rank\").fit(points)\n",
        "result = algo.predict(n_bkps=5) # number of breakpoints to detect\n",
        "print(result)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(df['Year'], points, label='J-D')\n",
        "palette = sns.color_palette(\"colorblind\")\n",
        "# Addinv vertical lines for change points\n",
        "for i, cp in enumerate(result[:-1]):\n",
        "    year = df['Year'].iloc[cp]\n",
        "    color = palette[i+1]\n",
        "    plt.axvline(x=year, color=color, linestyle='--', label=f'Change Points {i+1}')\n",
        "    plt.text(year, max(points), f'{year}', color=color, verticalalignment='top', horizontalalignment='right')\n",
        "    print(f\"Change Point {i+1}: Year {year}, Position {cp}\")\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.title('Change Point Detection for All-Year')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jkZXE5mpnR-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation:\n",
        "\n",
        "1. Titik Perubahan 1 (sekitar tahun 1930) Menandakan awal dari fase pemanasan awal yang dapat dikaitkan dengan efek jangka panjang dari Revolusi Industri tahap kedua.\n",
        "\n",
        "2. Titik Perubahan 2 (sekitar tahun 1940) Munculnya pola pendinginan sesaat (cooling phase) yang konsisten dengan anomali suhu global pasca Perang Dunia II, kemungkinan akibat dari perubahan aktivitas industri dan emisi aerosol.\n",
        "\n",
        "3. Titik Perubahan 3 (sekitar tahun 1950–1960) Pergeseran kembali menuju tren pemanasan, seiring dengan pertumbuhan industri pascaperang dan peningkatan emisi gas rumah kaca.\n",
        "\n",
        "4. Titik Perubahan 4 (sekitar tahun 1980) Awal dari periode pemanasan yang sangat signifikan—ditandai sebagai permulaan era modern dari percepatan pemanasan global.\n",
        "\n",
        "5. Titik Perubahan 5 (sekitar tahun 2000) Memperkuat bahwa dua dekade terakhir mengalami peningkatan suhu global yang tajam dan konsisten. Periode ini juga mencakup sebagian besar tahun terpanas dalam catatan sejarah modern."
      ],
      "metadata": {
        "id": "uEDaw_CFuafm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change Point Detection for Each Season"
      ],
      "metadata": {
        "id": "f-TQKq2juhjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ruptures as rpt\n",
        "\n",
        "season_names = {'DJF': 'Winter', 'MAM': 'Spring', 'JJA': 'Summer', 'SON': 'Fall'}\n",
        "for abb, season in season_names.items():\n",
        "    points = df[abb].values\n",
        "    print(points)\n",
        "\n",
        "    # Search, binary segmentation\n",
        "    algo = rpt.Binseg(model=\"rank\").fit(points)\n",
        "    result = algo.predict(n_bkps=5) # number of breakpoints to detect\n",
        "    print(result)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(df['Year'], points, label=f'{season}')\n",
        "    palette = sns.color_palette(\"colorblind\")\n",
        "\n",
        "    # Addinv vertical lines for change points\n",
        "    for i, cp in enumerate(result[:-1]):\n",
        "        year = df['Year'].iloc[cp]\n",
        "        color = palette[i+1]\n",
        "        plt.axvline(x=year, color=color, linestyle='--', label=f'Change Points {i+1}')\n",
        "        y_pos = max(points)\n",
        "        plt.text(year, y_pos, f'{year}', color=color, verticalalignment='top', horizontalalignment='right')\n",
        "        print(f\"Change Point {i+1}: Year {year}, Position {cp}, Y-Position {y_pos}\")\n",
        "\n",
        "    plt.xlabel('Year')\n",
        "    plt.title(f'Change Point Detection for {season}')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7tCZBxezueD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change Point Detection adalah teknik statistik yang digunakan untuk mengidentifikasi titik-titik waktu di mana terjadi perubahan signifikan dalam struktur data deret waktu. Dalam konteks ini, analisis dilakukan untuk masing-masing musim (Winter – DJF, Spring – MAM, Summer – JJA, dan Fall – SON) guna mendeteksi momen-momen penting yang mungkin menandai pergeseran tren suhu global musiman selama periode 1880–2023.\n",
        "\n",
        "Berdasarkan hasil visualisasi dan deteksi menggunakan metode Binary Segmentation dari pustaka ruptures, lima titik perubahan (change points) berhasil diidentifikasi pada setiap musim. Titik-titik ini menunjukkan periode di mana pola anomali suhu mengalami transisi signifikan. Misalnya:\n",
        "\n",
        "Winter (DJF): Titik perubahan muncul pada tahun 1885, 1935, 1945, 1980, dan 2015. Ini mencerminkan dinamika jangka panjang yang mungkin terkait dengan revolusi industri awal, dampak Perang Dunia II, dan percepatan pemanasan global di akhir abad ke-20 hingga awal abad ke-21.\n",
        "\n",
        "Spring (MAM): Deteksi menunjukkan perubahan besar sekitar tahun 1885, 1935, 1975, 1980, dan 2000, menunjukkan pergeseran pola musim semi yang konsisten dengan tren global.\n",
        "\n",
        "Summer (JJA): Titik-titik pada tahun 1900, 1930, 1940, 1980, dan 2005 mengindikasikan bahwa musim panas menjadi salah satu musim dengan perubahan suhu paling konsisten terhadap aktivitas antropogenik.\n",
        "\n",
        "Fall (SON): Tahun 1925, 1935, 1945, 1980, dan 2000 menunjukkan perubahan signifikan yang tampaknya sejajar dengan peristiwa besar dunia dan dinamika iklim global.\n",
        "\n",
        "Secara keseluruhan, pola titik perubahan yang terdeteksi di keempat musim memperkuat bukti adanya tren pemanasan global yang terjadi secara bertahap namun konsisten. Konsistensi tahun-tahun penting, seperti 1980 dan 2000, di seluruh musim, mencerminkan periode kritis dalam sejarah perubahan iklim yang perlu diperhatikan secara serius dalam perumusan kebijakan lingkungan dan mitigasi perubahan iklim."
      ],
      "metadata": {
        "id": "z05do6Q4FLY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting"
      ],
      "metadata": {
        "id": "EnD4lGBPxd-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARIMA (AutoRegressive Integrated Moving Average)"
      ],
      "metadata": {
        "id": "_o0KXp8axf4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare data for ARIMA**"
      ],
      "metadata": {
        "id": "hUu6McpUxmcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Convert 'Year' to datetime format & set it as the Index to prepare the data\n",
        "df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n",
        "df.set_index('Year', inplace=True)\n",
        "\n",
        "ts = df['J-D']\n",
        "ts"
      ],
      "metadata": {
        "id": "IpUd51FSxicR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Equpz61NkIYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tentukan ukuran data\n",
        "test_size = 3\n",
        "\n",
        "# Split data\n",
        "train = ts[:-test_size]  # 1880–2022\n",
        "test = ts[-test_size:]   # 2023–2025\n",
        "\n",
        "# Tampilkan hasil\n",
        "print(\"Train:\", train.index[0].year, \"→\", train.index[-1].year)\n",
        "print(\"Test:\", test.index[0].year, \"→\", test.index[-1].year)"
      ],
      "metadata": {
        "id": "C960IGEbj8ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk memastikan evaluasi model yang kuat dan menghindari overfitting, dataset dibagi menjadi dua bagian:\n",
        "1. Training Set (1880–2022): Digunakan untuk membangun dan melatih model ARIMA agar mampu mengenali pola historis dan tren jangka panjang.\n",
        "2. Test Set (2023–2025): Digunakan untuk menguji kinerja prediksi model terhadap data baru yang belum pernah dilihat sebelumnya."
      ],
      "metadata": {
        "id": "mBTuofv2H6BA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check for Stationarity**"
      ],
      "metadata": {
        "id": "1GRtF207x5Xt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADF (Augmented Dickey-Fuller) Test"
      ],
      "metadata": {
        "id": "iJcMiv2Qx95U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller #mengecek stasionaritas pada data time series.\n",
        "result = adfuller(train)  # Gantilah ts → train\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n"
      ],
      "metadata": {
        "id": "KjZl0AjSx-Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretasi:"
      ],
      "metadata": {
        "id": "TLSTw3PkIoAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai p-value sebesar 0.9946 sangat jauh di atas ambang batas signifikansi umum (α = 0.05), sehingga kita gagal menolak hipotesis nol (H₀) yang menyatakan bahwa data mengandung unit root (tidak stasioner). Dengan kata lain, data pelatihan menunjukkan pola non-stasioner, yang berarti mean dan variansnya tidak konstan sepanjang waktu."
      ],
      "metadata": {
        "id": "U3KFc-9RIaNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACF dan PACF Plot**"
      ],
      "metadata": {
        "id": "Xro4KwtmyLe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot ACF (Autocorrelation Function) menunjukkan tingkat korelasi antara nilai data dengan nilai-nilai sebelumnya (lag). Ini digunakan untuk membantu mengidentifikasi komponen Moving Average (MA), atau parameter q dalam model ARIMA. Jika ACF memiliki lonjakan besar di lag 1 dan penurunan cepat setelahnya, itu mengindikasikan kemungkinan model MA.(p) component.\n",
        "\n",
        "Plot PACF (Partial Autocorrelation Function) menunjukkan korelasi parsial antara suatu titik data dengan nilai-nilai sebelumnya setelah menghilangkan pengaruh lag perantara. Ini membantu menentukan komponen Autoregressive (AR), atau parameter p dalam model ARIMA. Lonjakan signifikan pada lag tertentu (misalnya lag 1 atau 2) dapat menjadi petunjuk nilai p."
      ],
      "metadata": {
        "id": "_PVDfdkDyIx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "plot_acf(train)\n",
        "plot_pacf(train)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SkYoTfj0uP0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan plot ACF dan PACF:\n",
        "\n",
        "ACF menurun perlahan → menunjukkan data non-stasioner, memerlukan differencing (d=1).\n",
        "\n",
        "PACF signifikan hanya di lag-1 → menunjukkan adanya pola autoregressive order 1 (p=1).\n",
        "\n",
        "Tidak ada pola jelas pada ACF setelah differencing → komponen MA (q) kemungkinan kecil atau q=0."
      ],
      "metadata": {
        "id": "KrWt94HwJJXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_diff = train.diff().dropna() #differencing (selisih antar nilai berurutan) pada time series untuk menghilangkan tren dan membuat data menjadi stasioner.\n",
        "ts_diff.plot()\n",
        "result_diff = adfuller(ts_diff) #menguji stationarity pada data yang sudah di-differencing.\n",
        "print('ADF Statistic: %f' % result_diff[0])\n",
        "print('p-value: %f' % result_diff[1])"
      ],
      "metadata": {
        "id": "FIe4f2g-yfMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai p-value < 0.05 dari uji ADF setelah differencing menunjukkan bahwa data telah menjadi stasioner. Oleh karena itu, parameter differencing (d) untuk model ARIMA dapat ditetapkan sebesar 1."
      ],
      "metadata": {
        "id": "hgmfcvkHyngu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Determind parameters p, q**"
      ],
      "metadata": {
        "id": "7mL--ovVytod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "fig, axes = plt.subplots(2,1,figsize=(12,8))\n",
        "# Autocorrelation funciton\n",
        "plot_acf(ts_diff, ax=axes[0])\n",
        "axes[0].set_title('Autocorrelation Function')\n",
        "axes[0].set_xlabel('Lags')\n",
        "axes[0].set_ylabel('Autocorrelation')\n",
        "# Partial autocorrelation function\n",
        "plot_pacf(ts_diff, ax=axes[1])\n",
        "axes[1].set_title('Partial Autocorrelation Function')\n",
        "axes[1].set_xlabel('Lags')\n",
        "axes[1].set_ylabel('Partial Autocorrelation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CViP3bxTyoWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large spike at lag 0 in both the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) plots, followed by non-significant spikes for subsequent lags, suggests that the series may not need additional AR (p) or MA (q) terms beyond the differencing that has been applied."
      ],
      "metadata": {
        "id": "8TLSXyn2y70a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fit the ARIMA Model**"
      ],
      "metadata": {
        "id": "6v8zHsKFy8iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ARIMA(ts_diff, order=(0,1,0)) #tidak menggunakan komponen autoregressive (AR), menggunakan 1 kali differencing (untuk menghilangkan tren), tidak menggunakan komponen moving average (MA).\n",
        "model_fit = model.fit()\n",
        "\n",
        "print(model_fit.summary())"
      ],
      "metadata": {
        "id": "-xGIGz_uy_JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting"
      ],
      "metadata": {
        "id": "5JQgINKA1GHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time-Series Predictions"
      ],
      "metadata": {
        "id": "vC8vaHYN1Kb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual and Density Plots\n",
        "resids = model_fit.resid[1:]\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(12,8))\n",
        "resids.plot(title='Residuals', ax=ax[0])\n",
        "resids.plot(title='Density', kind='kde', ax=ax[1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YwtyhksA287G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ===== Forecast berdasarkan ARIMA yang sudah dilatih =====\n",
        "# Forecast untuk 3 tahun ke depan (2023–2025)\n",
        "forecast_diff = model_fit.forecast(steps=3)\n",
        "last_value = train.iloc[-1]  # Koreksi di sini!\n",
        "forecast = forecast_diff.cumsum() + last_value\n",
        "\n",
        "# Buat index tahun 2023–2025\n",
        "future_years = pd.date_range(start='2023-01-01', periods=3, freq='YS')\n",
        "forecast_df = pd.DataFrame({'Year': future_years, 'Forecast': forecast}).set_index('Year')\n",
        "\n",
        "# ===== Plot =====\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 1. Plot data historis (training)\n",
        "plt.plot(ts.index, ts.values, label='Actual (Train)', color='blue')\n",
        "\n",
        "# 2. Plot forecast ARIMA (2023–2025)\n",
        "plt.plot(forecast_df.index, forecast_df['Forecast'], label='Forecast (ARIMA)', color='orange', linestyle='--', marker='o')\n",
        "\n",
        "# 3. Plot actual test data\n",
        "plt.plot(test.index, test.values, label='Actual (Test)', color='green', linestyle='-', marker='s')\n",
        "\n",
        "# 4. Highlight test period\n",
        "plt.axvspan(test.index[0], test.index[-1], color='gray', alpha=0.2, label='Test Period')\n",
        "\n",
        "# 5. Garis pembatas\n",
        "plt.axvline(x=test.index[0], color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# ===== Format tambahan =====\n",
        "plt.title('Forecast vs Actual (2023–2025)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly (J-D)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wjq8NgttFL2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
        "\n",
        "mae = mean_absolute_error(test, forecast_df)\n",
        "mape = mean_absolute_percentage_error(test, forecast_df)\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast_df))\n",
        "\n",
        "print(f'mae - manual: {mae}') #Rata-rata dari selisih absolut antara nilai aktual (test) dan hasil prediksi (forecast_df). Semakin kecil nilainya, semakin baik.\n",
        "print(f'mape - manual: {mape}') #Rata-rata dari selisih persentase absolut. Mengukur seberapa jauh prediksi dari nilai sebenarnya dalam bentuk persen.\n",
        "print(f'rmse - manual: {rmse}') #Akar dari MSE, memberikan penalti lebih besar untuk error yang besar dibanding MAE. Ini juga lebih sensitif terhadap outlier."
      ],
      "metadata": {
        "id": "HLshd_Licrl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Forecast 6 langkah (2023–2028)\n",
        "forecast_diff = model_fit.forecast(steps=6)\n",
        "\n",
        "# Gunakan nilai terakhir dari TRAINING SET (bukan seluruh ts)\n",
        "last_value = train.iloc[-1]\n",
        "forecast_values = forecast_diff.cumsum() + last_value\n",
        "\n",
        "# Buat index tahun prediksi (2023–2028)\n",
        "future_years = pd.date_range(start='2023-01-01', periods=6, freq='YS')\n",
        "\n",
        "# DataFrame hasil prediksi\n",
        "forecast_df2 = pd.DataFrame({\n",
        "    'Year': future_years,\n",
        "    'Forecast': forecast_values\n",
        "}).set_index('Year')\n",
        "\n",
        "# Pisahkan hasil prediksi untuk:\n",
        "forecast_test = forecast_df2.iloc[:3]   # 2023–2025\n",
        "forecast_future = forecast_df2.iloc[3:] # 2026–2028\n",
        "\n",
        "# ===== Plot =====\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 1. Data historis (1880–2025)\n",
        "plt.plot(ts.index, ts.values, label='Actual (Train + Val + Test)', color='blue')\n",
        "\n",
        "# 2. Forecast untuk test (2023–2025)\n",
        "plt.plot(forecast_test.index, forecast_test['Forecast'], label='Forecast (Test)', color='orange', linestyle='--', marker='o')\n",
        "\n",
        "# 3. Forecast ke depan (2026–2028)\n",
        "plt.plot(forecast_future.index, forecast_future['Forecast'], label='Forecast (2026–2028)', color='red', linestyle='--', marker='x')\n",
        "\n",
        "# 4. Data test aktual\n",
        "plt.plot(test.index, test.values, label='Actual (2023–2025)', color='green', linestyle='-', marker='s')\n",
        "\n",
        "# 5. Highlight test & future period\n",
        "plt.axvspan(test.index[0], test.index[-1], color='gray', alpha=0.2, label='Test Period')\n",
        "plt.axvspan(forecast_future.index[0], forecast_future.index[-1], color='yellow', alpha=0.2, label='Future Period')\n",
        "\n",
        "# 6. Garis pembatas test/future\n",
        "plt.axvline(x=test.index[0], color='red', linestyle='--', linewidth=1)\n",
        "plt.axvline(x=forecast_future.index[0], color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# ===== Format tambahan =====\n",
        "plt.title('Forecast vs Actual (2023–2028)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly (J-D)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wnOqryPadjis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.23.5 --force-reinstall --no-cache-dir\n",
        "!pip install scipy==1.9.3 --force-reinstall --no-cache-dir\n",
        "!pip install statsmodels==0.13.5 --force-reinstall --no-cache-dir\n",
        "!pip install pmdarima==2.0.3 --force-reinstall --no-cache-dir"
      ],
      "metadata": {
        "id": "FTpqIQ6aLCCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-ARIMA"
      ],
      "metadata": {
        "id": "QqVBKJKdEUNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pmdarima import auto_arima\n",
        "\n",
        "model_auto = auto_arima(train, start_p=1, start_q=1,\n",
        "                   test='adf',       # Use adftest to find optimal 'd'\n",
        "                   max_p=5, max_q=5, # Maximum p and q\n",
        "                   m=1,              # Frequency of the series\n",
        "                   d=None,           # Let the model determine 'd'\n",
        "                   seasonal=False,   # No Seasonality\n",
        "                   start_P=0,        #Tidak mencari komponen musiman.\n",
        "                   D=0,\n",
        "                   trace=True,      #Tampilkan log saat pencarian model.\n",
        "                   error_action='ignore', #Abaikan error dan lanjutkan pencarian model.\n",
        "                   suppress_warnings=True, #Sembunyikan peringatan saat proses fitting.\n",
        "                   stepwise=True) # Gunakan pendekatan stepwise untuk efisiensi pencarian model terbaik.\n",
        "\n",
        "print(model_auto.summary())"
      ],
      "metadata": {
        "id": "Eknc_ZiTEaYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual and Density Plots\n",
        "resids = pd.Series(model_auto.resid())\n",
        "\n",
        "fig, ax = plt.subplots(1,2,figsize=(12,8))\n",
        "resids.plot(title='Residuals', ax=ax[0])\n",
        "resids.plot(title='Density', kind='kde', ax=ax[1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GKf6WVerOqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have two ARIMA models: ARIMA(0, 1, 0) and the auto-fitted ARIMA(3, 1, 1). Let’s compare and evaluate their predictions."
      ],
      "metadata": {
        "id": "GsU_epwaUBo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pmdarima import auto_arima\n",
        "# ===== Forecast berdasarkan ARIMA yang sudah dilatih =====\n",
        "# Forecast untuk 3 tahun ke depan (2023–2025)\n",
        "forecast_diff = model_auto.predict(n_periods=3)\n",
        "last_value = train.iloc[-1]  # Koreksi di sini!\n",
        "forecast = forecast_diff.cumsum() + last_value\n",
        "\n",
        "# Buat index tahun 2023–2025\n",
        "future_years = pd.date_range(start='2023-01-01', periods=3, freq='YS')\n",
        "forecast_df = pd.DataFrame({'Year': future_years, 'Forecast': forecast}).set_index('Year')\n",
        "\n",
        "# ===== Plot =====\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 1. Plot data historis (training)\n",
        "plt.plot(ts.index, ts.values, label='Actual (Train)', color='blue')\n",
        "\n",
        "# 2. Plot forecast ARIMA (2023–2025)\n",
        "plt.plot(forecast_df.index, forecast_df['Forecast'], label='Forecast (ARIMA)', color='orange', linestyle='--', marker='o')\n",
        "\n",
        "# 3. Plot actual test data\n",
        "plt.plot(test.index, test.values, label='Actual (Test)', color='green', linestyle='-', marker='s')\n",
        "\n",
        "# 4. Highlight test period\n",
        "plt.axvspan(test.index[0], test.index[-1], color='gray', alpha=0.2, label='Test Period')\n",
        "\n",
        "# 5. Garis pembatas\n",
        "plt.axvline(x=test.index[0], color='red', linestyle='--', linewidth=1)\n",
        "\n",
        "# ===== Format tambahan =====\n",
        "plt.title('Forecast vs Actual (2023–2025) Auto ARIMA')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly (J-D)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q0fzjMnAdPQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(test, forecast_df)\n",
        "mape = mean_absolute_percentage_error(test, forecast_df)\n",
        "rmse = np.sqrt(mean_squared_error(test, forecast_df))\n",
        "\n",
        "print(f'mae - auto: {mae}')\n",
        "print(f'mape - auto: {mape}')\n",
        "print(f'rmse - auto: {rmse}')"
      ],
      "metadata": {
        "id": "4oCE8Tt-eaOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Forecast dengan ARIMA manual ===\n",
        "forecast_manual_diff = model_fit.forecast(steps=6)\n",
        "last_value_manual = train.iloc[-1]\n",
        "forecast_manual = forecast_manual_diff.cumsum() + last_value_manual\n",
        "\n",
        "# === Forecast dengan auto-ARIMA ===\n",
        "forecast_auto = model_auto.predict(n_periods=6)\n",
        "last_value_auto = train.iloc[-1]\n",
        "forecast_auto = pd.Series(forecast_auto).cumsum() + last_value_auto\n",
        "\n",
        "# Buat index tahun prediksi (2023–2028)\n",
        "future_years = pd.date_range(start='2023-01-01', periods=6, freq='YS')\n",
        "\n",
        "# DataFrame hasil prediksi\n",
        "forecast_df_manual = pd.DataFrame({\n",
        "    'Year': future_years,\n",
        "    'Forecast_Manual': forecast_manual\n",
        "}).set_index('Year')\n",
        "\n",
        "forecast_df_auto = pd.DataFrame({\n",
        "    'Year': future_years,\n",
        "    'Forecast_Auto': forecast_auto\n",
        "}).set_index('Year')\n",
        "\n",
        "# Gabungkan hasil forecast\n",
        "forecast_df3 = pd.concat([forecast_df_manual, forecast_df_auto], axis=1)\n",
        "\n",
        "# ===== Plot =====\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# 1. Data historis\n",
        "plt.plot(ts.index, ts.values, label='Actual (Train + Test)', color='blue')\n",
        "\n",
        "# 2. Forecast ARIMA manual (2023–2028)\n",
        "plt.plot(forecast_df3.index, forecast_df3['Forecast_Manual'], label='Forecast (Manual ARIMA)', color='orange', linestyle='--', marker='o')\n",
        "\n",
        "# 3. Forecast Auto-ARIMA (2023–2028)\n",
        "plt.plot(forecast_df3.index, forecast_df3['Forecast_Auto'], label='Forecast (Auto-ARIMA)', color='purple', linestyle='--', marker='x')\n",
        "\n",
        "# 4. Data test aktual\n",
        "plt.plot(test.index, test.values, label='Actual (2023–2025)', color='green', linestyle='-', marker='s')\n",
        "\n",
        "# 5. Highlight test & future period\n",
        "plt.axvspan(test.index[0], test.index[-1], color='gray', alpha=0.2, label='Test Period')\n",
        "plt.axvspan(forecast_df3.index[3], forecast_df3.index[-1], color='yellow', alpha=0.2, label='Future Period')\n",
        "\n",
        "# 6. Garis pembatas\n",
        "plt.axvline(x=test.index[0], color='red', linestyle='--')\n",
        "plt.axvline(x=forecast_df3.index[3], color='red', linestyle='--')\n",
        "\n",
        "# Format tambahan\n",
        "plt.title('Manual ARIMA vs Auto-ARIMA Forecast (2023–2028)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Temperature Anomaly (J-D)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DjO3OKC4UQMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we plot both models’ predictions together, you can see that the manually fitted model of ARIMA(0, 1, 0) is closer to the actual test set."
      ],
      "metadata": {
        "id": "0a5KxoHhUwVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from matplotlib.collections import LineCollection\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "# Forecast 6 langkah (2023–2028)\n",
        "forecast_diff = model_fit.forecast(steps=6)\n",
        "last_value = train.iloc[-1]\n",
        "forecast_values = forecast_diff.cumsum() + last_value\n",
        "\n",
        "# Buat index tahun prediksi\n",
        "future_years = pd.date_range(start='2023-01-01', periods=6, freq='YS')\n",
        "forecast_df2 = pd.DataFrame({'Forecast': forecast_values}, index=future_years)\n",
        "\n",
        "# Gabungkan data train dan prediksi (1880–2028)\n",
        "combined = pd.concat([train, forecast_df2['Forecast']])\n",
        "combined.index = pd.to_datetime(combined.index)  # Pastikan index datetime\n",
        "combined = combined.dropna()  # Hindari masalah NaN\n",
        "\n",
        "# Konversi datetime ke angka (float)\n",
        "dates_dt = pd.to_datetime(combined.index)\n",
        "x = mdates.date2num(dates_dt)\n",
        "y = combined.values\n",
        "\n",
        "# Siapkan segmen garis\n",
        "points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
        "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
        "\n",
        "# Warna suhu (gradasi biru ke merah)\n",
        "norm = plt.Normalize(vmin=-1, vmax=1)\n",
        "cmap = plt.cm.bwr\n",
        "colors = cmap(norm(y[:-1]))\n",
        "\n",
        "# Siapkan plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.set_xlim(x[0], x[-1])\n",
        "ax.set_ylim(y.min() - 0.1, y.max() + 0.1)\n",
        "ax.set_title('Time-lapse Suhu Global: 1880–2028')\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Temperature Anomaly (J-D)')\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "\n",
        "# LineCollection utama\n",
        "line_collection = LineCollection([], linewidth=2)\n",
        "ax.add_collection(line_collection)\n",
        "\n",
        "# Shadow trail (semi transparan)\n",
        "shadow_collection = LineCollection([], linewidth=4, alpha=0.3)\n",
        "ax.add_collection(shadow_collection)\n",
        "\n",
        "# Titik animasi\n",
        "point, = ax.plot([], [], 'o', markersize=8)\n",
        "\n",
        "# Inisialisasi animasi\n",
        "def init():\n",
        "    line_collection.set_segments([])\n",
        "    shadow_collection.set_segments([])\n",
        "    point.set_data([], [])\n",
        "    return line_collection, shadow_collection, point\n",
        "\n",
        "# Update animasi per frame\n",
        "def update(frame):\n",
        "    if frame == 0:\n",
        "        return init()\n",
        "\n",
        "    segs = segments[:frame]\n",
        "    seg_colors = colors[:frame]\n",
        "\n",
        "    line_collection.set_segments(segs)\n",
        "    line_collection.set_color(seg_colors)\n",
        "\n",
        "    # Shadow trail effect\n",
        "    trail_len = 10\n",
        "    start = max(0, frame - trail_len)\n",
        "    shadow_collection.set_segments(segments[start:frame])\n",
        "    shadow_collection.set_color(colors[start:frame])\n",
        "\n",
        "    point.set_data([x[frame]], [y[frame]])\n",
        "    point.set_color(cmap(norm(y[frame])))\n",
        "\n",
        "    return line_collection, shadow_collection, point\n",
        "\n",
        "# Buat animasi\n",
        "anim = FuncAnimation(fig, update, frames=len(combined), init_func=init,\n",
        "                     blit=True, interval=50)\n",
        "\n",
        "plt.close()  # Supress extra figure\n",
        "HTML(anim.to_jshtml())\n"
      ],
      "metadata": {
        "id": "uOv4YlJQgjmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qdbd7Ql5gjYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5zIT6v3PUyx-"
      }
    }
  ]
}